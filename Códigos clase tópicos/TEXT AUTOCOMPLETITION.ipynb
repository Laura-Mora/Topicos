{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gutenberg.org/cache/epub/41445/pg41445.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 32\n",
    "BATCH_SIZE = 256\n",
    "INPUT_FILE_NAME = 'C:/Users/pipel/Documents/Javeriana Topicos/Sesion 3/Version 2/Frankenstein.txt'\n",
    "WINDOW_LENGTH = 40\n",
    "WINDOW_STEP = 3\n",
    "BEAM_SIZE = 8\n",
    "NUM_LETTERS = 11\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir el archivo\n",
    "file = open(INPUT_FILE_NAME, 'r', encoding='utf-8')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "# convertir el texto a minusculas y quitar saltos de linea y espacios adicionales\n",
    "text = text.lower()\n",
    "text = text.replace('\\n', ' ')\n",
    "text = text.replace('\\ufeff', ' ')\n",
    "text = text.replace('  ', '')\n",
    "\n",
    "# codificar caracteres como indices\n",
    "unique_chars = list(set(text))\n",
    "char_to_index = dict((ch, index) for index,\n",
    "                    ch in enumerate(unique_chars))\n",
    "index_to_char = dict((index, ch) for index,\n",
    "                    ch in enumerate(unique_chars))\n",
    "encoding_with = len(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'ë': 1,\n",
       " '*': 2,\n",
       " '’': 3,\n",
       " 'b': 4,\n",
       " 'z': 5,\n",
       " '-': 6,\n",
       " '5': 7,\n",
       " 'g': 8,\n",
       " 'ô': 9,\n",
       " '#': 10,\n",
       " 'q': 11,\n",
       " ';': 12,\n",
       " '(': 13,\n",
       " ')': 14,\n",
       " ':': 15,\n",
       " '1': 16,\n",
       " 'w': 17,\n",
       " 't': 18,\n",
       " '7': 19,\n",
       " '.': 20,\n",
       " 'â': 21,\n",
       " 'i': 22,\n",
       " '‘': 23,\n",
       " 'j': 24,\n",
       " '_': 25,\n",
       " '“': 26,\n",
       " 'p': 27,\n",
       " '4': 28,\n",
       " '&': 29,\n",
       " 'f': 30,\n",
       " '2': 31,\n",
       " 's': 32,\n",
       " ',': 33,\n",
       " '3': 34,\n",
       " 'k': 35,\n",
       " '8': 36,\n",
       " '—': 37,\n",
       " 'ê': 38,\n",
       " '%': 39,\n",
       " '$': 40,\n",
       " '6': 41,\n",
       " 'm': 42,\n",
       " '[': 43,\n",
       " 'e': 44,\n",
       " 'o': 45,\n",
       " 'r': 46,\n",
       " ']': 47,\n",
       " 'a': 48,\n",
       " '”': 49,\n",
       " '?': 50,\n",
       " '9': 51,\n",
       " 'y': 52,\n",
       " 'h': 53,\n",
       " 'u': 54,\n",
       " 'v': 55,\n",
       " '/': 56,\n",
       " '0': 57,\n",
       " 'c': 58,\n",
       " 'd': 59,\n",
       " 'n': 60,\n",
       " 'æ': 61,\n",
       " '!': 62,\n",
       " 'x': 63,\n",
       " 'l': 64}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragment:  the project gutenberg ebook of frankens      Target: t\n",
      "fragment: e project gutenberg ebook of frankenstei      Target: n\n"
     ]
    }
   ],
   "source": [
    "#crear Window\n",
    "fragments = []\n",
    "targets = []\n",
    "\n",
    "for i in range (0, len(text)- WINDOW_LENGTH, WINDOW_STEP):\n",
    "    fragments.append (text [i : i+WINDOW_LENGTH])\n",
    "    targets.append(text[i+WINDOW_LENGTH])\n",
    "    \n",
    "print('fragment: '+fragments[0] + '      Target: ' + targets[0])\n",
    "print('fragment: '+fragments[1] + '      Target: ' + targets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "\n",
    "x = np.zeros((len(fragments), WINDOW_LENGTH, encoding_with))\n",
    "y = np.zeros((len(fragments), encoding_with))\n",
    "\n",
    "for i, fragment in enumerate(fragments):\n",
    "    for j, char in enumerate(fragment):\n",
    "        x[i,j, char_to_index[char]] = 1\n",
    "    target_char = targets[i]\n",
    "    y[i, char_to_index[target_char]] = 1\n",
    "    \n",
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 128)         99328     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 65)                8385      \n",
      "=================================================================\n",
      "Total params: 239,297\n",
      "Trainable params: 239,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Entrenar Modelo\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True,\n",
    "                    dropout=0.2,\n",
    "                    recurrent_dropout=0.2,\n",
    "                    input_shape=(None,encoding_with)))\n",
    "\n",
    "model.add(LSTM(128, dropout=0.2,\n",
    "                    recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(encoding_with, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134581 samples, validate on 7084 samples\n",
      "Epoch 1/32\n",
      "134581/134581 [==============================] - 181s 1ms/sample - loss: 2.8813 - val_loss: 2.7389\n",
      "Epoch 2/32\n",
      "134581/134581 [==============================] - 172s 1ms/sample - loss: 2.5297 - val_loss: 2.5967\n",
      "Epoch 3/32\n",
      "134581/134581 [==============================] - 184s 1ms/sample - loss: 2.4239 - val_loss: 2.4971\n",
      "Epoch 4/32\n",
      "134581/134581 [==============================] - 189s 1ms/sample - loss: 2.3501 - val_loss: 2.4549\n",
      "Epoch 5/32\n",
      "134581/134581 [==============================] - 190s 1ms/sample - loss: 2.2972 - val_loss: 2.4023\n",
      "Epoch 6/32\n",
      "134581/134581 [==============================] - 205s 2ms/sample - loss: 2.2528 - val_loss: 2.3633\n",
      "Epoch 7/32\n",
      "134581/134581 [==============================] - 206s 2ms/sample - loss: 2.2182 - val_loss: 2.3415\n",
      "Epoch 8/32\n",
      "134581/134581 [==============================] - 213s 2ms/sample - loss: 2.1850 - val_loss: 2.3133\n",
      "Epoch 9/32\n",
      "134581/134581 [==============================] - 230s 2ms/sample - loss: 2.1638 - val_loss: 2.2867\n",
      "Epoch 10/32\n",
      "134581/134581 [==============================] - 240s 2ms/sample - loss: 2.1372 - val_loss: 2.2682\n",
      "Epoch 11/32\n",
      "134581/134581 [==============================] - 278s 2ms/sample - loss: 2.1148 - val_loss: 2.2600\n",
      "Epoch 12/32\n",
      "134581/134581 [==============================] - 267s 2ms/sample - loss: 2.0985 - val_loss: 2.2329\n",
      "Epoch 13/32\n",
      "134581/134581 [==============================] - 294s 2ms/sample - loss: 2.0784 - val_loss: 2.2329\n",
      "Epoch 14/32\n",
      "134581/134581 [==============================] - 299s 2ms/sample - loss: 2.0654 - val_loss: 2.2187\n",
      "Epoch 15/32\n",
      "134581/134581 [==============================] - 307s 2ms/sample - loss: 2.0539 - val_loss: 2.2004\n",
      "Epoch 16/32\n",
      "134581/134581 [==============================] - 330s 2ms/sample - loss: 2.0352 - val_loss: 2.2045\n",
      "Epoch 17/32\n",
      "134581/134581 [==============================] - 334s 2ms/sample - loss: 2.0266 - val_loss: 2.1795\n",
      "Epoch 18/32\n",
      "134581/134581 [==============================] - 347s 3ms/sample - loss: 2.0133 - val_loss: 2.1842\n",
      "Epoch 19/32\n",
      "134581/134581 [==============================] - 358s 3ms/sample - loss: 2.0020 - val_loss: 2.1758\n",
      "Epoch 20/32\n",
      "134581/134581 [==============================] - 388s 3ms/sample - loss: 1.9909 - val_loss: 2.1543\n",
      "Epoch 21/32\n",
      "134581/134581 [==============================] - 388s 3ms/sample - loss: 1.9831 - val_loss: 2.1596\n",
      "Epoch 22/32\n",
      "134581/134581 [==============================] - 405s 3ms/sample - loss: 1.9761 - val_loss: 2.1618\n",
      "Epoch 23/32\n",
      "134581/134581 [==============================] - 419s 3ms/sample - loss: 1.9664 - val_loss: 2.1428\n",
      "Epoch 24/32\n",
      "134581/134581 [==============================] - 429s 3ms/sample - loss: 1.9555 - val_loss: 2.1513\n",
      "Epoch 25/32\n",
      "134581/134581 [==============================] - 448s 3ms/sample - loss: 1.9483 - val_loss: 2.1358\n",
      "Epoch 26/32\n",
      "134581/134581 [==============================] - 470s 3ms/sample - loss: 1.9457 - val_loss: 2.1308\n",
      "Epoch 27/32\n",
      "134581/134581 [==============================] - 488s 4ms/sample - loss: 1.9384 - val_loss: 2.1331\n",
      "Epoch 28/32\n",
      "134581/134581 [==============================] - 511s 4ms/sample - loss: 1.9290 - val_loss: 2.1273\n",
      "Epoch 29/32\n",
      "134581/134581 [==============================] - 534s 4ms/sample - loss: 1.9239 - val_loss: 2.1277\n",
      "Epoch 30/32\n",
      "134581/134581 [==============================] - 549s 4ms/sample - loss: 1.9163 - val_loss: 2.1190\n",
      "Epoch 31/32\n",
      "134581/134581 [==============================] - 563s 4ms/sample - loss: 1.9093 - val_loss: 2.1193\n",
      "Epoch 32/32\n",
      "134581/134581 [==============================] - 584s 4ms/sample - loss: 1.9079 - val_loss: 2.1146\n"
     ]
    }
   ],
   "source": [
    "#ejecutar modelo\n",
    "\n",
    "history = model.fit(x, y, validation_split=0.05,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear un beam inicial\n",
    "\n",
    "letters = 'the body '\n",
    "one_hots = []\n",
    "for i, char in enumerate(letters):\n",
    "    x = np.zeros(encoding_with)\n",
    "    x[char_to_index[char]] = 1\n",
    "    one_hots.append(x)\n",
    "\n",
    "beams = [(np.log(1.0), letters, one_hots)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the body of the count of the \n",
      "the body of the death of the \n",
      "the body of the should of the\n",
      "the body of the countion of t\n",
      "the body of the should of my \n",
      "the body of the countion of m\n",
      "the body of the countion of h\n",
      "the body of the countion of a\n"
     ]
    }
   ],
   "source": [
    "#predecir letras futuras\n",
    "\n",
    "for i in range(NUM_LETTERS):\n",
    "    minibatch_list =[]\n",
    "    \n",
    "    #crear minibatch desde one-hot y predecir\n",
    "    for triple in beams:\n",
    "        minibatch_list.append(triple[2])\n",
    "        \n",
    "    minibatch = np.array(minibatch_list)\n",
    "    y_predict = model.predict(minibatch, verbose=0)\n",
    "    new_beams = []\n",
    "    \n",
    "    for j, softmax_vec in enumerate (y_predict):\n",
    "        triple = beams[j]\n",
    "        #crea nuevos beams desde los existentes\n",
    "        for k in range(BEAM_SIZE):\n",
    "            char_index = np.argmax(softmax_vec)\n",
    "            new_prob = triple[0] + np.log(softmax_vec[char_index])\n",
    "            new_letters = triple[1] + index_to_char[char_index]\n",
    "            x = np.zeros(encoding_with)\n",
    "            x[char_index]=1\n",
    "            new_one_hots = triple[2].copy()\n",
    "            new_one_hots.append(x)\n",
    "            new_beams.append((new_prob, new_letters, new_one_hots))\n",
    "            softmax_vec[char_index]=0\n",
    "        \n",
    "    #limpiar el arbol para quedarse con los beams mas probables\n",
    "    new_beams.sort(key=lambda tup: tup[0], reverse=True)\n",
    "    beams = new_beams[0:BEAM_SIZE]\n",
    "    \n",
    "for item in beams:\n",
    "    print(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
