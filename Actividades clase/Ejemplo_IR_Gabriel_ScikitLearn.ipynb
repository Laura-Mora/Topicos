{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NLP - IR\n",
        "### Luis Gabriel Moreno Sandoval\n",
        "### morenoluis@javeriana.edu.co"
      ],
      "metadata": {
        "id": "dFGFonUOwHZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.stem import SnowballStemmer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words_english = nltk.corpus.stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kmOzZNzBpNC",
        "outputId": "8e3b9288-244d-4d6f-dda9-60ec8b6c7bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(text):\n",
        "  #print('before pre_process', text)\n",
        "  text = text.lower()\n",
        "  #print('after pre_process', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "_vS1HfTRBux4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_stemmer(text):\n",
        "  tokens_doc = nltk.word_tokenize(text)\n",
        "  tokens_doc_wo_stop = [w for w in tokens_doc if w.isalpha()]\n",
        "  tokens_docs_stem = [stemmer.stem(w) for w in tokens_doc_wo_stop]\n",
        "  return tokens_docs_stem"
      ],
      "metadata": {
        "id": "Ex0-AEB3CqJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9s8FlcNBNWD",
        "outputId": "7bb9d356-f04a-48a7-9a46-97afcd0427d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'might', 'must', 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'veri', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blue', 'cat', 'egg', 'fish', 'green', 'ham', 'hat', 'one', 'red', 'two']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "docs_raw = []\n",
        "#docs_raw.append(\"\"\"El precio del dólar en el mercado interbancario colombiano inició este jueves con relativa estabilidad en su negociación y sin mayores sobre saltos, característicos de las últimas semanas.\n",
        "#Este jueves, el dólar en Colombia vivió su segunda jornada seguida con pérdidas. Sin embargo, a pesar de la bajada en su precio, la divisa se mantuvo arriba de los 4.500 pesos.\"\"\")\n",
        "docs_raw.append('one fish, two fish')\n",
        "docs_raw.append('Red fish, blue fish')\n",
        "docs_raw.append('cat in The Hat')\n",
        "docs_raw.append('Green eggs and ham')\n",
        "#docs_raw.append('Green eggs and ham')\n",
        "#docs_raw.append('Green eggs and ham')\n",
        "\n",
        "tfidf = TfidfVectorizer(preprocessor=pre_process, tokenizer=tokenize_stemmer, stop_words=stop_words_english)\n",
        "# tfidf = TfidfVectorizer()\n",
        "tfs = tfidf.fit_transform(docs_raw)\n",
        "tfidf.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_num, feature_num = tfs.shape\n",
        "feature_names = tfidf.get_feature_names()\n",
        "print(\"n_docs: %d, n_features: %d\" % tfs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQFkM4wiFamK",
        "outputId": "abaed53a-841e-4faa-a039-bca5e610d2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_docs: 4, n_features: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"###### Calculo de Feature Names ######\")\n",
        "for x in range(0, feature_num):\n",
        "    print(\" # \", x ,\" - \",feature_names[x], \" - \", [tfs[n,x] for n in range(0, docs_num)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOrW9JBNF1ZJ",
        "outputId": "10b7fcac-b602-4b2d-8658-6f54106693c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###### Calculo de Feature Names ######\n",
            " #  0  -  blue  -  [0.0, 0.47212002654617047, 0.0, 0.0]\n",
            " #  1  -  cat  -  [0.0, 0.0, 0.7071067811865476, 0.0]\n",
            " #  2  -  egg  -  [0.0, 0.0, 0.0, 0.5773502691896257]\n",
            " #  3  -  fish  -  [0.7444497035180324, 0.7444497035180324, 0.0, 0.0]\n",
            " #  4  -  green  -  [0.0, 0.0, 0.0, 0.5773502691896257]\n",
            " #  5  -  ham  -  [0.0, 0.0, 0.0, 0.5773502691896257]\n",
            " #  6  -  hat  -  [0.0, 0.0, 0.7071067811865476, 0.0]\n",
            " #  7  -  one  -  [0.47212002654617047, 0.0, 0.0, 0.0]\n",
            " #  8  -  red  -  [0.0, 0.47212002654617047, 0.0, 0.0]\n",
            " #  9  -  two  -  [0.47212002654617047, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = tfidf.transform([\"one fish hat hat\", \"blue eggs hat\", \"fish, otra palabra blues\"])\n",
        "print('response:', response)\n",
        "cosine_similarity_response =  cosine_similarity(response, tfs)\n",
        "print(\"n_question: %d, n_features: %d\" % response.shape)\n",
        "print(\"cosine_similarity \", cosine_similarity_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4eb9ynbGJ7r",
        "outputId": "9651b087-9f56-4b97-e878-8f54fd96c893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response:   (0, 7)\t0.4217647821447532\n",
            "  (0, 6)\t0.8435295642895064\n",
            "  (0, 3)\t0.3325241986862672\n",
            "  (1, 6)\t0.5773502691896257\n",
            "  (1, 2)\t0.5773502691896257\n",
            "  (1, 0)\t0.5773502691896257\n",
            "  (2, 3)\t0.6191302964899972\n",
            "  (2, 0)\t0.7852882757103967\n",
            "n_question: 3, n_features: 10\n",
            "cosine_similarity  [[0.44667114 0.24754754 0.59646548 0.        ]\n",
            " [0.         0.27257862 0.40824829 0.33333333]\n",
            " [0.46091137 0.83166169 0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ckriju271Y4V",
        "outputId": "9d5cff4f-25df-4364-bb24-713812902162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x10 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 8 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZZ1oev02ksP",
        "outputId": "5e137c75-9369-496e-8c07-874738472fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump\n",
        "from datetime import datetime\n",
        "data_filename_memmap = f\"file_tfidf_{datetime.now().strftime('%Y-%m-%d')}.vec\"\n",
        "dump(tfidf, data_filename_memmap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSp1_YdX3ita",
        "outputId": "c5d7c547-11cb-42f1-aa47-de147dc88f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['file_tfidf_2022-09-10.vec']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load\n",
        "tf_idf_2_re = load('file_tfidf_2022-09-10.vec', mmap_mode='r')"
      ],
      "metadata": {
        "id": "FkD8w2wq4sRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = tf_idf_2_re.transform([\"fish blue cat persona\"])\n",
        "print('response:', response)\n",
        "cosine_similarity_response =  cosine_similarity(response, tfs)\n",
        "print(\"n_question: %d, n_features: %d\" % response.shape)\n",
        "print(\"cosine_similarity \", cosine_similarity_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjDxsJKp467y",
        "outputId": "c4a9545b-4e23-47b4-9aae-227f2f4ba804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response:   (0, 3)\t0.48693426407352264\n",
            "  (0, 1)\t0.6176143709756019\n",
            "  (0, 0)\t0.6176143709756019\n",
            "n_question: 1, n_features: 10\n",
            "cosine_similarity  [[0.36249807 0.65408618 0.43671931 0.        ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'might', 'must', 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'veri', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "def proper_encoding(text):\n",
        "    # print('text: ', text)\n",
        "    text = unicodedata.normalize('NFD', text)\n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "An19Prqn7tPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Holá Miño otro lingüística.\"\n",
        "print(proper_encoding(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Bk3Q4P71hQ",
        "outputId": "f8e2a4ed-c8b4-4ef3-fef4-dff7564ca982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola Mino otro linguistica.\n"
          ]
        }
      ]
    }
  ]
}